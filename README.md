# FL Security Papers

A list of interesting papers on attacks and defenses on Federated Learning (FL)

I think we should focus on Active MIAs, as they capture this sense of the central server manipulating the model to extract infromation. I attached 2 papers. 

## Attacks

## Differential Privacy

- Athanasiou et al. [**"Enhancing Metric Privacy With a Shuffler"**](https://hal.science/hal-04895564/document) @ **PETS 2025**.
- Diaz et al. [**"Metric Privacy in Federated Learning for Medical Imaging: Improving Convergence and Preventing Client Inference Attacks"**](https://arxiv.org/pdf/2502.01352) @ **Arxiv 2025**.

## Anonymity

- Agiollo et al. [**"Anonymous Federated Learning via Named-Data Networking"**](https://www.sciencedirect.com/science/article/pii/S0167739X23004144) @ **FGCS 2024**.

## Active MIAs
-  **Active Membership Inference Attack under Local Differential Privacy in Federated Learning** ( https://proceedings.mlr.press/v206/nguyen23e/nguyen23e.pdf)
- **Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning** (https://arxiv.org/pdf/1812.00910)


## Gradient Disaggregation
-  **Gradient Disaggregation: Breaking Privacy in Federated Learning by Reconstructing the User Participant Matrix** (https://proceedings.mlr.press/v139/lam21b/lam21b.pdf)
- **Quality Inference in Federated Learning with Secure Aggregation.** (https://arxiv.org/pdf/2007.06236)
-  **Eluding Secure Aggregation in Federated Learning via Model Inconsistency.**  (https://arxiv.org/pdf/2111.07380)
-  **SRATTA: SAMPLE RE-ATTRIBUTION ATTACK OF SECURE AGGREGATION IN FEDERATED LEARNING** (https://arxiv.org/pdf/2306.07644)
